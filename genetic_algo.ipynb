{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb29e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\DELL\\.cache\\kagglehub\\datasets\\cabaki\\knycmetars2016\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"cabaki/knycmetars2016\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c370dcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in dataset: ['KNYC_Metars.csv']\n",
      "                  Time  Temp.  Windchill  Heat Index  Humidity  Pressure  \\\n",
      "0  2015-12-31 02:00:00    7.8        7.1         NaN      0.89    1017.0   \n",
      "1  2015-12-31 03:00:00    7.2        5.9         NaN      0.90    1016.5   \n",
      "2  2015-12-31 04:00:00    7.2        NaN         NaN      0.90    1016.7   \n",
      "3  2015-12-31 05:00:00    7.2        5.9         NaN      0.86    1015.9   \n",
      "4  2015-12-31 06:00:00    7.2        6.4         NaN      0.90    1016.2   \n",
      "\n",
      "   Dew Point  Visibility  Wind Dir  Wind Speed  Gust Speed  Precip Events  \\\n",
      "0        6.1         8.0       NNE         5.6         0.0     0.8    NaN   \n",
      "1        5.6        12.9  Variable         7.4         0.0     0.3    NaN   \n",
      "2        5.6        12.9      Calm         0.0         0.0     0.0    NaN   \n",
      "3        5.0        14.5        NW         7.4         0.0     0.0    NaN   \n",
      "4        5.6        11.3      West         5.6         0.0     0.0    NaN   \n",
      "\n",
      "  Conditions  \n",
      "0   Overcast  \n",
      "1   Overcast  \n",
      "2   Overcast  \n",
      "3   Overcast  \n",
      "4   Overcast  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8787 entries, 0 to 8786\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Time        8787 non-null   object \n",
      " 1   Temp.       8787 non-null   float64\n",
      " 2   Windchill   2295 non-null   float64\n",
      " 3   Heat Index  815 non-null    float64\n",
      " 4   Humidity    8787 non-null   float64\n",
      " 5   Pressure    8556 non-null   float64\n",
      " 6   Dew Point   8787 non-null   float64\n",
      " 7   Visibility  8550 non-null   float64\n",
      " 8   Wind Dir    8787 non-null   object \n",
      " 9   Wind Speed  8787 non-null   float64\n",
      " 10  Gust Speed  8787 non-null   float64\n",
      " 11  Precip      8787 non-null   float64\n",
      " 12  Events      455 non-null    object \n",
      " 13  Conditions  8787 non-null   object \n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 961.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Check files in the dataset folder\n",
    "print(\"Files in dataset:\", os.listdir(path))\n",
    "\n",
    "# Pick the CSV file (replace with the actual filename you see)\n",
    "csv_file = [f for f in os.listdir(path) if f.endswith(\".csv\")][0]\n",
    "csv_path = os.path.join(path, csv_file)\n",
    "\n",
    "# Load the CSV\n",
    "weather_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Show first 5 rows\n",
    "print(weather_df.head())\n",
    "\n",
    "# Optional: see basic info about dataset\n",
    "print(weather_df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6e2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df[\"Time\"] = pd.to_datetime(weather_df[\"Time\"])\n",
    "weather_df[\"pickup_year\"] = weather_df[\"Time\"].dt.year\n",
    "weather_df[\"pickup_month\"] = weather_df[\"Time\"].dt.month\n",
    "weather_df[\"pickup_day\"] = weather_df[\"Time\"].dt.day\n",
    "weather_df[\"pickup_hour\"] = weather_df[\"Time\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f55e516c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Overcast', 'Clear', 'Partly Cloudy', 'Mostly Cloudy',\n",
       "       'Scattered Clouds', 'Unknown', 'Light Rain', 'Haze', 'Rain',\n",
       "       'Heavy Rain', 'Light Snow', 'Snow', 'Heavy Snow',\n",
       "       'Light Freezing Fog', 'Light Freezing Rain', 'Fog'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at weather conditions\n",
    "weather_df[\"Conditions\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c50905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codify weather conditions into buckets\n",
    "weather_df[\"Conditions\"] =  weather_df[\"Conditions\"].fillna('Unknown')\n",
    "\n",
    "weather_dict = {'Overcast' : 0, \n",
    "                'Haze' : 0,\n",
    "                'Partly Cloudy' : 0, \n",
    "                'Mostly Cloudy' : 0, \n",
    "                'Scattered Clouds' : 0, \n",
    "                'Light Freezing Fog' : 0,\n",
    "                'Fog' : 0,\n",
    "                'Cloudy' : 0,\n",
    "                \n",
    "                'Unknown' : 1,\n",
    "                'Clear' : 2, \n",
    "                \n",
    "                'Heavy Rain' : 3, \n",
    "                'Rain' : 3, \n",
    "                'Light Freezing Rain' : 3,\n",
    "                'Light Rain' : 3, \n",
    "                \n",
    "                'Heavy Snow' : 4,\n",
    "                'Light Snow' : 4,\n",
    "                'Snow' : 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7bef428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the column\n",
    "weather_df[\"Conditions\"] =  weather_df[\"Conditions\"].apply(lambda x: weather_dict[x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff52450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NNE', 'Variable', 'Calm', 'NW', 'West', 'WNW', 'North', 'WSW',\n",
       "       'NE', 'SSW', 'SW', 'ENE', 'SE', 'East', 'ESE', 'South', 'SSE',\n",
       "       'NNW'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at wind directions\n",
    "weather_df[\"Wind Dir\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86a8b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codify wind directions\n",
    "weather_df[\"Wind Dir\"] = weather_df[\"Wind Dir\"].fillna('Unknown')\n",
    "\n",
    "wind_dir_dict = {'East' : 0,\n",
    "                 'ENE' : 0, \n",
    "                 'ESE' : 0, \n",
    "                 \n",
    "                 'West' : 1, \n",
    "                 'WSW' : 1,\n",
    "                 'WNW' : 1,\n",
    "                 \n",
    "                 'South' : 2, \n",
    "                 'SSE' : 2,   \n",
    "                 'SSW' : 2,\n",
    "                 \n",
    "                 'North' : 3, \n",
    "                 'NNE' : 3, \n",
    "                 'NNW' : 3,\n",
    "                 \n",
    "                 'Variable' : 4, \n",
    "                 'Calm' : 5, \n",
    "                 'SW' : 6, \n",
    "                 'NW' : 7, \n",
    "                 'NE' : 8, \n",
    "                 'SE' : 9, \n",
    "                 'Unknown' : 10\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0bbf2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#And transform the column\n",
    "weather_df[\"Wind Dir\"] = weather_df[\"Wind Dir\"].apply(lambda x: wind_dir_dict[x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d06f7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Temp.</th>\n",
       "      <th>Windchill</th>\n",
       "      <th>Heat Index</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Dew Point</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Wind Dir</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Gust Speed</th>\n",
       "      <th>Precip</th>\n",
       "      <th>Events</th>\n",
       "      <th>Conditions</th>\n",
       "      <th>pickup_year</th>\n",
       "      <th>pickup_month</th>\n",
       "      <th>pickup_day</th>\n",
       "      <th>pickup_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-31 02:00:00</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-31 03:00:00</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-31 04:00:00</td>\n",
       "      <td>7.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-31 05:00:00</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1015.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>7</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-31 06:00:00</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1016.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time  Temp.  Windchill  Heat Index  Humidity  Pressure  \\\n",
       "0 2015-12-31 02:00:00    7.8        7.1         NaN      0.89    1017.0   \n",
       "1 2015-12-31 03:00:00    7.2        5.9         NaN      0.90    1016.5   \n",
       "2 2015-12-31 04:00:00    7.2        NaN         NaN      0.90    1016.7   \n",
       "3 2015-12-31 05:00:00    7.2        5.9         NaN      0.86    1015.9   \n",
       "4 2015-12-31 06:00:00    7.2        6.4         NaN      0.90    1016.2   \n",
       "\n",
       "   Dew Point  Visibility  Wind Dir  Wind Speed  Gust Speed  Precip Events  \\\n",
       "0        6.1         8.0         3         5.6         0.0     0.8    NaN   \n",
       "1        5.6        12.9         4         7.4         0.0     0.3    NaN   \n",
       "2        5.6        12.9         5         0.0         0.0     0.0    NaN   \n",
       "3        5.0        14.5         7         7.4         0.0     0.0    NaN   \n",
       "4        5.6        11.3         1         5.6         0.0     0.0    NaN   \n",
       "\n",
       "   Conditions  pickup_year  pickup_month  pickup_day  pickup_hour  \n",
       "0           0         2015            12          31            2  \n",
       "1           0         2015            12          31            3  \n",
       "2           0         2015            12          31            4  \n",
       "3           0         2015            12          31            5  \n",
       "4           0         2015            12          31            6  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de100d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'Temp.', 'Windchill', 'Heat Index', 'Humidity', 'Pressure',\n",
      "       'Dew Point', 'Visibility', 'Wind Dir', 'Wind Speed', 'Gust Speed',\n",
      "       'Precip', 'Events', 'Conditions', 'pickup_year', 'pickup_month',\n",
      "       'pickup_day', 'pickup_hour'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(weather_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc85d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df['Time'] = pd.to_datetime(weather_df['Time'])   # convert to datetime\n",
    "weather_df['date'] = weather_df['Time'].dt.date           # extract date\n",
    "weather_df['hour'] = weather_df['Time'].dt.hour           # extract hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a22691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from copy import copy\n",
    "import datetime\n",
    "import pickle\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50260987",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"xgb_model.sav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27611746",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93e721d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample date\n",
    "\n",
    "date_list = [4, 6, 2016] #April 6, 2016\n",
    "\n",
    "year = int(date_list[2])\n",
    "month = int(date_list[1])\n",
    "day = int(date_list[0])\n",
    "\n",
    "my_date = datetime.date(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b138a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample test locations\n",
    "\n",
    "test_locations = {'L1': (40.819688, -73.915091),\n",
    "                  'L2': (40.815421, -73.941761),\n",
    "                  'L3': (40.764198, -73.910785),\n",
    "                  'L4': (40.768790, -73.953285),\n",
    "                  'L5': (40.734851, -73.952950),\n",
    "                  'L6': (40.743613, -73.977998),\n",
    "                  'L7': (40.745313, -73.993793),\n",
    "                  'L8': (40.662713, -73.946101),\n",
    "                  'L9': (40.703761, -73.886496),\n",
    "                  'L10': (40.713620, -73.943076),\n",
    "                  'L11': (40.725212, -73.809179)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4976096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "# Provide a unique user_agent\n",
    "geolocator = Nominatim(user_agent=\"nyc_taxi_weather_project\")\n",
    "\n",
    "addresses = []\n",
    "for key in test_locations:\n",
    "    location = geolocator.reverse(test_locations[key])\n",
    "    if location:\n",
    "        addresses.append(location.address)\n",
    "    else:\n",
    "        addresses.append(None)\n",
    "    \n",
    "    # Sleep to respect Nominatim usage policy (avoid rate limit)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ce6c718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['424, East 155th Street, Melrose, The Bronx, Bronx County, City of New York, New York, 10455, United States',\n",
       " '137, West 136th Street, Manhattan Community Board 10, Manhattan, New York County, City of New York, New York, 10030, United States',\n",
       " 'Citi Bike - 28 Av / 44 St, 28th Avenue, Queens, Queens County, City of New York, New York, 11377, United States',\n",
       " '435, East 74th Street, Lenox Hill, Manhattan Community Board 8, Manhattan, New York County, City of New York, New York, 10021, United States',\n",
       " '211, Freeman Street, Greenpoint, Brooklyn, Kings County, City of New York, New York, 11222, United States',\n",
       " '232, East 32nd Street, Murray Hill, Manhattan Community Board 6, Manhattan, New York County, City of New York, New York, 10016, United States',\n",
       " '159, West 25th Street, Chelsea, Manhattan Community Board 4, Manhattan, New York County, City of New York, New York, 10001, United States',\n",
       " '486, Brooklyn Avenue, Crown Heights, Brooklyn, Kings County, City of New York, New York, 11225, United States',\n",
       " '70-38, 67th Place, Glendale, Queens, Queens County, City of New York, New York, 11385, United States',\n",
       " '194, Devoe Street, Williamsburg, Brooklyn, Kings County, City of New York, New York, 11211, United States',\n",
       " '158-46, 76th Avenue, Utopia, Queens, Queens County, City of New York, New York, 11366, United States']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b53712ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_addresses = {'L1': '424 East 155th Street NY',\n",
    "                  'L2': '137 West 136th Street NY',\n",
    "                  'L3': '43-11 28th Avenue NY',\n",
    "                  'L4': '435 East 74th Street NY',\n",
    "                  'L5': '211 Freeman Street NY',\n",
    "                  'L6': '232 East 32nd Street NY',\n",
    "                  'L7': '159 West 25th Street NY',\n",
    "                  'L8': '486 Brooklyn Avenue NY',\n",
    "                  'L9': '70-38 67th Place NY',\n",
    "                  'L10': '194 Devoe Street NY',\n",
    "                  'L11': '158-46 76th Avenue NY'\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4201d1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L4', 'L10', 'L5', 'L9', 'L7', 'L3', 'L8', 'L1', 'L6', 'L11', 'L2', 'L4']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_guess(points):\n",
    "    \"\"\"\n",
    "    Creates a possible path between all points, returning to the original.\n",
    "    Input: List of point IDs\n",
    "    \"\"\"\n",
    "    guess = copy(points)\n",
    "    np.random.shuffle(guess)\n",
    "    guess.append(guess[0])\n",
    "    return list(guess)\n",
    "\n",
    "create_guess(list(test_locations.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e48fc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['L3', 'L2', 'L6', 'L4', 'L7', 'L11', 'L8', 'L5', 'L10', 'L1', 'L9', 'L3'], ['L3', 'L10', 'L5', 'L11', 'L8', 'L1', 'L7', 'L9', 'L2', 'L4', 'L6', 'L3'], ['L11', 'L10', 'L7', 'L8', 'L2', 'L3', 'L9', 'L5', 'L6', 'L4', 'L1', 'L11'], ['L3', 'L10', 'L5', 'L2', 'L11', 'L7', 'L8', 'L1', 'L4', 'L6', 'L9', 'L3'], ['L3', 'L9', 'L11', 'L2', 'L7', 'L4', 'L5', 'L6', 'L8', 'L10', 'L1', 'L3'], ['L6', 'L7', 'L2', 'L10', 'L3', 'L8', 'L5', 'L9', 'L4', 'L1', 'L11', 'L6'], ['L6', 'L7', 'L5', 'L9', 'L11', 'L3', 'L8', 'L4', 'L1', 'L2', 'L10', 'L6'], ['L2', 'L4', 'L9', 'L1', 'L6', 'L11', 'L10', 'L3', 'L5', 'L8', 'L7', 'L2'], ['L3', 'L1', 'L4', 'L9', 'L7', 'L10', 'L2', 'L8', 'L5', 'L6', 'L11', 'L3'], ['L1', 'L6', 'L5', 'L8', 'L10', 'L9', 'L11', 'L7', 'L2', 'L4', 'L3', 'L1']]\n"
     ]
    }
   ],
   "source": [
    "def create_generation(points, population=100):\n",
    "    \"\"\"\n",
    "    Makes a list of guessed point orders given a list of point IDs.\n",
    "    Input:\n",
    "    points: list of point ids\n",
    "    population: how many guesses to make\n",
    "    \"\"\"\n",
    "    generation = [create_guess(points) for _ in range(population)]\n",
    "    return generation\n",
    "\n",
    "test_generation = create_generation(list(test_locations.keys()), population=10)\n",
    "print(test_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aef36fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def travel_time_between_points(point1_id, point2_id, hour, date,\n",
    "                               passenger_count=1, store_and_fwd_flag=0,\n",
    "                               pickup_minute=0,\n",
    "                               weather_data=None):\n",
    "    \"\"\"\n",
    "    Given two points, this calculates travel between them based on XGBoost predictive model\n",
    "    (now includes weather features).\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Base trip features ---\n",
    "    model_data = {\n",
    "        'passenger_count': passenger_count,\n",
    "        'pickup_longitude': point1_id[1],\n",
    "        'pickup_latitude': point1_id[0],\n",
    "        'dropoff_longitude': point2_id[1],\n",
    "        'dropoff_latitude': point2_id[0],\n",
    "        'store_and_fwd_flag': store_and_fwd_flag,\n",
    "        'pickup_month': my_date.month,\n",
    "        'pickup_day': my_date.day,\n",
    "        'pickup_weekday': my_date.weekday(),\n",
    "        'pickup_hour': hour,\n",
    "        'pickup_minute': pickup_minute,\n",
    "        'latitude_difference': point2_id[0] - point1_id[0],\n",
    "        'longitude_difference': point2_id[1] - point1_id[1],\n",
    "        'trip_distance': 0.621371 * 6371 * (\n",
    "            abs(2 * np.arctan2(\n",
    "                np.sqrt(np.square(np.sin((abs(point2_id[0] - point1_id[0]) * np.pi / 180) / 2))),\n",
    "                np.sqrt(1 - (np.square(np.sin((abs(point2_id[0] - point1_id[0]) * np.pi / 180) / 2))))\n",
    "            )) +\n",
    "            abs(2 * np.arctan2(\n",
    "                np.sqrt(np.square(np.sin((abs(point2_id[1] - point1_id[1]) * np.pi / 180) / 2))),\n",
    "                np.sqrt(1 - (np.square(np.sin((abs(point2_id[1] - point1_id[1]) * np.pi / 180) / 2))))\n",
    "            ))\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # --- Weather features (looked up from provided dict or DataFrame) ---\n",
    "    if weather_data is not None:\n",
    "        weather_row = weather_data.loc[\n",
    "            (weather_data['date'] == date) & (weather_data['hour'] == hour)\n",
    "        ]\n",
    "        if not weather_row.empty:\n",
    "            model_data.update({\n",
    "                'Temp.': weather_row['Temp.'].values[0],\n",
    "                'Windchill': weather_row['Windchill'].values[0],\n",
    "                'Humidity': weather_row['Humidity'].values[0],\n",
    "                'Pressure': weather_row['Pressure'].values[0],\n",
    "                'Dew Point': weather_row['Dew Point'].values[0],\n",
    "                'Visibility': weather_row['Visibility'].values[0],\n",
    "                'Wind Dir': weather_row['Wind Dir'].values[0],\n",
    "                'Wind Speed': weather_row['Wind Speed'].values[0],\n",
    "                'Gust Speed': weather_row['Gust Speed'].values[0],\n",
    "                'Precip': weather_row['Precip'].values[0],\n",
    "                'Conditions': weather_row['Conditions'].values[0]\n",
    "        \n",
    "            })\n",
    "    \n",
    "    \n",
    "    # --- Prediction ---\n",
    "    df = pd.DataFrame([model_data], columns=model_data.keys())\n",
    "    pred = np.exp(loaded_model.predict(xgb.DMatrix(df))) - 1\n",
    "    return pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c34f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = test_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3cb2cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['L3', 'L2', 'L6', 'L4', 'L7', 'L11', 'L8', 'L5', 'L10', 'L1', 'L9', 'L3'], np.float32(2.7018132)), (['L3', 'L10', 'L5', 'L11', 'L8', 'L1', 'L7', 'L9', 'L2', 'L4', 'L6', 'L3'], np.float32(3.0889826)), (['L11', 'L10', 'L7', 'L8', 'L2', 'L3', 'L9', 'L5', 'L6', 'L4', 'L1', 'L11'], np.float32(2.953683)), (['L3', 'L10', 'L5', 'L2', 'L11', 'L7', 'L8', 'L1', 'L4', 'L6', 'L9', 'L3'], np.float32(3.5290666)), (['L3', 'L9', 'L11', 'L2', 'L7', 'L4', 'L5', 'L6', 'L8', 'L10', 'L1', 'L3'], np.float32(1.9834836)), (['L6', 'L7', 'L2', 'L10', 'L3', 'L8', 'L5', 'L9', 'L4', 'L1', 'L11', 'L6'], np.float32(3.0846548)), (['L6', 'L7', 'L5', 'L9', 'L11', 'L3', 'L8', 'L4', 'L1', 'L2', 'L10', 'L6'], np.float32(2.0448604)), (['L2', 'L4', 'L9', 'L1', 'L6', 'L11', 'L10', 'L3', 'L5', 'L8', 'L7', 'L2'], np.float32(2.7666602)), (['L3', 'L1', 'L4', 'L9', 'L7', 'L10', 'L2', 'L8', 'L5', 'L6', 'L11', 'L3'], np.float32(3.0315294)), (['L1', 'L6', 'L5', 'L8', 'L10', 'L9', 'L11', 'L7', 'L2', 'L4', 'L3', 'L1'], np.float32(1.6165377))]\n"
     ]
    }
   ],
   "source": [
    "def fitness_score(guess, weather_data=None):\n",
    "    \"\"\"\n",
    "    Loops through the points in the guesses order and calculates\n",
    "    how much distance the path would take to complete a loop.\n",
    "    Lower is better.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    for ix, point_id in enumerate(guess[:-1]):\n",
    "        score += travel_time_between_points(\n",
    "            coordinates[point_id],\n",
    "            coordinates[guess[ix+1]],\n",
    "            11,  # hour\n",
    "            my_date, \n",
    "            weather_data=weather_data\n",
    "        )\n",
    "    return score\n",
    "\n",
    "\n",
    "def check_fitness(guesses, weather_data=None):\n",
    "    \"\"\"\n",
    "    Goes through every guess and calculates the fitness score. \n",
    "    Returns a list of tuples: (guess, fitness_score)\n",
    "    \"\"\"\n",
    "    fitness_indicator = []\n",
    "    for guess in guesses:\n",
    "        fitness_indicator.append(\n",
    "            (guess, fitness_score(guess, weather_data=weather_data))\n",
    "        )\n",
    "    return fitness_indicator\n",
    "\n",
    "\n",
    "# Example call\n",
    "print(check_fitness(test_generation, weather_data=weather_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be5aade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_breeders_from_generation(guesses, take_best_N=10, take_random_N=5, verbose=False, mutation_rate=0.1,weather_data=None):\n",
    "    \"\"\"\n",
    "    This sets up the breeding group for the next generation. You have\n",
    "    to be very careful how many breeders you take, otherwise your\n",
    "    population can explode. These two, plus the \"number of children per couple\"\n",
    "    in the make_children function must be tuned to avoid exponential growth or decline!\n",
    "    \"\"\"\n",
    "    # First, get the top guesses from last time\n",
    "    fit_scores = check_fitness(guesses, weather_data=weather_data)\n",
    "    sorted_guesses = sorted(fit_scores, key=lambda x: x[1]) # sorts so lowest is first, which we want\n",
    "    new_generation = [x[0] for x in sorted_guesses[:take_best_N]]\n",
    "    best_guess = new_generation[0]\n",
    "    \n",
    "    if verbose:\n",
    "        # If we want to see what the best current guess is!\n",
    "        print(best_guess)\n",
    "    \n",
    "    # Second, get some random ones for genetic diversity\n",
    "    for _ in range(take_random_N):\n",
    "        ix = np.random.randint(len(guesses))\n",
    "        new_generation.append(guesses[ix])\n",
    "        \n",
    "    # No mutations here since the order really matters.\n",
    "    # If we wanted to, we could add a \"swapping\" mutation,\n",
    "    # but in practice it doesn't seem to be necessary\n",
    "    \n",
    "    np.random.shuffle(new_generation)\n",
    "    return new_generation, best_guess\n",
    "\n",
    "def make_child(parent1, parent2):\n",
    "    \"\"\" \n",
    "    Take some values from parent 1 and hold them in place, then merge in values\n",
    "    from parent2, filling in from left to right with cities that aren't already in \n",
    "    the child. \n",
    "    \"\"\"\n",
    "    list_of_ids_for_parent1 = list(np.random.choice(parent1, replace=False, size=len(parent1)//2))\n",
    "    child = [-99 for _ in parent1]\n",
    "    for ix in range(0, len(list_of_ids_for_parent1)):\n",
    "        child[ix] = parent1[ix]\n",
    "    for ix, gene in enumerate(child):\n",
    "        if gene == -99:\n",
    "            for gene2 in parent2:\n",
    "                if gene2 not in child:\n",
    "                    child[ix] = gene2\n",
    "                    break\n",
    "    child[-1] = child[0]\n",
    "    return child\n",
    "\n",
    "def make_children(old_generation, children_per_couple=1):\n",
    "    \"\"\"\n",
    "    Pairs parents together, and makes children for each pair. \n",
    "    If there are an odd number of parent possibilities, one \n",
    "    will be left out. \n",
    "    \n",
    "    Pairing happens by pairing the first and last entries. \n",
    "    Then the second and second from last, and so on.\n",
    "    \"\"\"\n",
    "    mid_point = len(old_generation)//2\n",
    "    next_generation = [] \n",
    "    \n",
    "    for ix, parent in enumerate(old_generation[:mid_point]):\n",
    "        for _ in range(children_per_couple):\n",
    "            next_generation.append(make_child(parent, old_generation[-ix-1]))\n",
    "    return next_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "650358c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: 500\n",
      "['L1', 'L7', 'L4', 'L3', 'L5', 'L8', 'L9', 'L11', 'L10', 'L6', 'L2', 'L1']\n",
      "Generation 5: 525\n",
      "['L5', 'L10', 'L1', 'L2', 'L7', 'L6', 'L4', 'L8', 'L9', 'L11', 'L3', 'L5']\n",
      "Generation 10: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 15: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 20: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 25: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 30: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 35: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 40: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 45: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 50: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 55: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 60: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 65: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 70: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 75: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 80: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 85: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 90: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n",
      "Generation 95: 525\n",
      "['L6', 'L9', 'L8', 'L10', 'L5', 'L11', 'L3', 'L4', 'L1', 'L2', 'L7', 'L6']\n"
     ]
    }
   ],
   "source": [
    "current_generation = create_generation(list(test_locations.keys()),population=500)\n",
    "print_every_n_generations = 5\n",
    "\n",
    "for i in range(100):\n",
    "    if not i % print_every_n_generations:\n",
    "        print(\"Generation %i: \"%i, end='')\n",
    "        print(len(current_generation))\n",
    "        is_verbose = True\n",
    "    else:\n",
    "        is_verbose = False\n",
    "    breeders, best_guess = get_breeders_from_generation(current_generation, \n",
    "                                                        take_best_N=250, take_random_N=100, \n",
    "                                                        verbose=is_verbose,weather_data=weather_df)\n",
    "    current_generation = make_children(breeders, children_per_couple=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b62d847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L9', 'L8', 'L10', 'L11']\n",
      "Generation 10: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 15: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 20: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 25: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 30: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 35: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 40: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 45: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 50: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 55: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 60: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 65: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 70: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 75: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 80: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 85: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 90: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n",
      "Generation 95: 330\n",
      "Current Best Score:  0.78119355\n",
      "['L11', 'L3', 'L5', 'L1', 'L6', 'L7', 'L2', 'L4', 'L10', 'L8', 'L9', 'L11']\n"
     ]
    }
   ],
   "source": [
    "def evolve_to_solve(current_generation, max_generations, take_best_N, take_random_N,\n",
    "                    mutation_rate, children_per_couple, print_every_n_generations, verbose=False,weather_data=None):\n",
    "    \"\"\"\n",
    "    Takes in a generation of guesses then evolves them over time using our breeding rules.\n",
    "    Continue this for \"max_generations\" times.\n",
    "    Inputs:\n",
    "    current_generation: The first generation of guesses\n",
    "    max_generations: how many generations to complete\n",
    "    take_best_N: how many of the top performers get selected to breed\n",
    "    take_random_N: how many random guesses get brought in to keep genetic diversity\n",
    "    mutation_rate: How often to mutate (currently unused)\n",
    "    children_per_couple: how many children per breeding pair\n",
    "    print_every_n_geneartions: how often to print in verbose mode\n",
    "    verbose: Show printouts of progress\n",
    "    Returns:\n",
    "    fitness_tracking: a list of the fitness score at each generations\n",
    "    best_guess: the best_guess at the end of evolution\n",
    "    \"\"\"\n",
    "    fitness_tracking = []\n",
    "    for i in range(max_generations):\n",
    "        if verbose and not i % print_every_n_generations and i > 0:\n",
    "            print(\"Generation %i: \"%i, end='')\n",
    "            print(len(current_generation))\n",
    "            print(\"Current Best Score: \", fitness_tracking[-1])\n",
    "            is_verbose = True\n",
    "        else:\n",
    "            is_verbose = False\n",
    "        breeders, best_guess = get_breeders_from_generation(current_generation, \n",
    "                                                            take_best_N=take_best_N, take_random_N=take_random_N, \n",
    "                                                            verbose=is_verbose, mutation_rate=mutation_rate,weather_data=weather_df)\n",
    "        fitness_tracking.append(fitness_score(best_guess, weather_data=weather_data))\n",
    "        current_generation = make_children(breeders, children_per_couple=children_per_couple)\n",
    "    \n",
    "    return fitness_tracking, best_guess\n",
    "\n",
    "current_generation = create_generation(list(test_locations.keys()),population=500)\n",
    "fitness_tracking, best_guess = evolve_to_solve(current_generation, 100, 150, 70, 0.5, 3, 5, verbose=True, weather_data=weather_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel_itinerary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
